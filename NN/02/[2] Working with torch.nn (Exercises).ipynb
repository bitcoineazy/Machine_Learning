{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание архитектуры нейронной сети посредством модуля torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейронные сети состоят из слоев, которые производят преобразования над данными. В PyTorch принято называть слои ***модулями*** (modules), и далее мы тоже будем использовать это название.\n",
    "\n",
    "Для большей чёткости в структуре нейронной сети используются классы. В PyTorch есть отдельный класс [torch.nn](https://pytorch.org/docs/stable/nn.html), специально созданный для работы с нейронными сетями. В нём уже реализованы все типы слоёв и функций активации. Это позволяет существенно сократить код и упростить работу с нейронными сетями.\n",
    "\n",
    "Пространство имен [`torch.nn`](https://pytorch.org/docs/stable/nn.html) предоставляет \"строительные блоки\", которые нужны для создания своей собственной нейронной сети. Каждый *модуль* в PyTorch является дочерним классом от [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). Таким образом, нейронная сеть сама по себе будет являться *модулем*, состоящим из других *модулей* (слоев). Такая вложенная структура позволяет легко создавать сложные архитектуры и управлять ими.\n",
    "\n",
    "Сначала импортируем модуль (from torch import nn) и потом обращаемся к нему:\n",
    "функция активации ReLU --- nn.ReLU();\n",
    "функция активации sigmoid --- nn.Sigmoid();\n",
    "линейный слой --- nn.Linear();\n",
    "свёрточный слой --- nn.Conv2d() и т.д.\n",
    "\n",
    "Рассмотрим основные \"строительные блоки\", при помощи которых мы будем создавать нейронные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подмодуль torch.nn.Module --- описание класса модели\n",
    "\n",
    "Мы определяем нейронную сеть, наследуясь от класса `nn.Module`, и инициализируем ее слои в методе `__init__`. Каждый класс-наследник `nn.Module` производит операции над входными данными в методе `forward`.\n",
    "\n",
    "Множество слоев в нейронных сетях имеют *обучаемые параметры*, т. е. имеют ассоциированные с ними веса и смещения, которые оптимизируются во время обучения.\n",
    "\n",
    "Наследование от `nn.Module` автоматически отслеживает все слои, определенные внутри вашего класса модели, и делает все их параметры доступными с помощью методов `model.parameters()` или `model.named_parameters()`.\n",
    "\n",
    "Создадим на базе класса `nn.Module` свой собственный класс, который будет его наследником. В качестве объекта возьмём нейронную сеть из предыдущего раздела:\n",
    "\n",
    "<img src='assets/multilayer_diagram_weights.png' width=\"1000\">\n",
    "\n",
    "Эта простая нейронная сеть состоит из двух линейных слоёв: первый размером $3 \\times 2$ с последующим применением функции активации ReLU, второй размером $2 \\times 1$. Обращаю внимание на метод forward() --- именно он отвечает за \"проход по нейронной сети\". Строгое определение: процесс передачи значений от входных нейронов к выходным называется прямым распространением (forward pass)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала подключим необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потом создадим класс через наследование от класса `nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden = nn.Linear(3, 2)\n",
    "        self.output = nn.Linear(2, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # функция прохода входного изображения сквозь нейронную сеть.\n",
    "        x = self.hidden(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы использовать модель, необходимо передать ей входные данные. Это приводит в действие метод `forward`, а также определенные фоновые операции. Не следует вызывать `model.forward` напрямую!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим случайный входной вектор размерности $1 \\times 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3544, 0.3143, 0.3333])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(3)\n",
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы начать работу с построенной нейронной сетью, необходимо сначала создать экземпляр описанного класса Network()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обращении к этому классу получим описание структуры созданной нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=3, out_features=2, bias=True)\n",
       "  (output): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь \"пропустим\" через полученную нейронную сеть созданный нами входной вектор input, выведем на экран полученный результат и его размерность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2239], grad_fn=<AddBackward0>)\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "result = model(input)\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку выходное множество состоит из одного элемента, извлечём его явное значение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22389058768749237"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подмодули для функций активации\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/neurons_output.png\" width=\"1000\">\n",
    "\n",
    "Функции активации должны обладать следующими свойствами:\n",
    "\n",
    "* **Нелинейность:** функция активации необходима для введения нелинейности в нейронные сети. Если функция активации не применяется, выходной сигнал становится простой линейной функцией. Нейронная сеть без нелинейностей будет действовать как линейная модель с ограниченной способностью к обучению:\n",
    "$$\\hat{y}=NN(X,W_1,...,W_n)=X\\cdot W_1\\cdot ...\\cdot W_n=X\\cdot W$$\n",
    "Только нелинейные функции активации позволяют нейронным сетям решать задачи аппроксимации нелинейных функций:\n",
    "$$\\hat{y}=NN(X,W_1,...,W_n)=\\sigma(...\\sigma(X\\cdot W_1)...\\cdot W_n)\\neq X\\cdot W$$\n",
    "\n",
    "* **Дифференцируемость:** функции активации должны быть способными пропускать градиент, чтобы было возможно оптимизировать параметры сети градиентными методами, в частности использовать алгоритм обратного распространения ошибки.\n",
    "\n",
    "\n",
    "Любая функция активации задаётся просто своим названием: nn.ReLU, nn.Tanh, nn.Sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подмодуль для линейного слоя nn.Linear\n",
    "\n",
    "Линейный слой [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) — это модуль, который производит линейное преобразование входных данных с помощью хранящихся в нем весов и смещений.\n",
    "\n",
    "Обязательными параметрами при объявлении этого слоя являются `in_features` — количество входных признаков, и `out_features` — количество выходных признаков.\n",
    "\n",
    "Фактически, этот модуль добавляет в модель один полносвязный слой нейронов *без активаций*. Слой состоит из `out_features` нейронов, каждый из которых имеет `in_features` входов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подмодуль для объединения слоёв в одну последовательность nn.Sequential\n",
    "\n",
    "[`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) — это упорядоченный контейнер для модулей. Данные проходят через все модули в том же порядке, в котором они определены в `nn.Sequential`. Можно использовать такой контейнер для того, чтобы быстро собрать простую нейронную сеть, что мы и сделаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подмодуль nn.Flatten\n",
    "\n",
    "Мы используем слой nn.Flatten для преобразования каждого изображения 1×28×28 пикселей в непрерывный массив из 784 значений (размер батча (на позиции dim=0) сохраняется)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подмодуль для результирующего слоя nn.Softmax\n",
    "\n",
    "Последний линейный слой нейронной сети возвращает *логиты* — \"сырые\" значения из диапазона $[-∞; +∞]$, которые могут быть пропущены через модуль [`nn.Softmax`](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html). Пропущенные через $\\text{sofmax}$ величины могут восприниматься как вероятности, с которыми модель относит данный объект к тому или иному классу. Параметр `dim` определяет размерность, вдоль которой величины должны суммироваться к $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример применения всех описанных подмодулей\n",
    "\n",
    "Для иллюстрации возьмем мини-батч (в данном случае представленный тензором, заполненным случайными числами) из трех одноканальных изображений $28 \\times 28$ и посмотрим, что с ним происходит, когда мы пропускаем его через сеть.\n",
    "Обращаю внимание, что изображения хранятся в разных форматах, здесь будем использовать размерность (batch_size, channels, height, width).\n",
    "Итак, создаём тензор указанной размерности и выводим его размер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([3, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = torch.rand(3, 1, 28, 28)\n",
    "print(f\"Input size: {sample_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вытянем наши тестовые изображения в один вектор и выведем его размер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Flatten: torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(sample_batch)\n",
    "print(f\"Size after Flatten: {flat_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее объявим линейный слой из 512 нейронов, каждый из которых получает \"вытянутое\" изображение из 784 пикселей. Пропустим через него это изображение и выведем на экран его размерность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Linear:  torch.Size([3, 512])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(784, 512)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(f\"Size after Linear:  {hidden1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейный слой, в отличие от слоя `nn.Flatten`, имеет обучаемые параметры — веса и смещения. Они хранятся как объекты специального класса `torch.nn.parameter.Parameter` и содержат в себе тензоры собственно с величинами параметров. Получить доступ к ним можно, обратившись к атрибутам слоя `.weight` и `.bias` соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of linear layer weights: torch.Size([512, 784])\n",
      "Type of linear layer weights: <class 'torch.nn.parameter.Parameter'>\n",
      "\n",
      "Size of linear layer biases: torch.Size([512])\n",
      "Type of linear layer biases: <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of linear layer weights: {layer1.weight.size()}\")\n",
    "print(f\"Type of linear layer weights: {type(layer1.weight)}\")\n",
    "\n",
    "print(f\"\\nSize of linear layer biases: {layer1.bias.size()}\")\n",
    "print(f\"Type of linear layer biases: {type(layer1.bias)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь применим функцию ReLU к выходному значению линейного слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU:  tensor([[ 0.1087, -0.2381, -0.0866,  ..., -0.4481, -0.3227,  0.1224],\n",
      "        [ 0.2015, -0.0524, -0.1890,  ..., -0.3673, -0.1507, -0.2399],\n",
      "        [ 0.1642,  0.0528, -0.4793,  ..., -0.2664, -0.1327, -0.2854]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "After ReLU:  tensor([[0.1087, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1224],\n",
      "        [0.2015, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1642, 0.0528, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "\n",
      " Size after ReLU:  torch.Size([3, 512])\n"
     ]
    }
   ],
   "source": [
    "activations1 = nn.ReLU()(hidden1)\n",
    "\n",
    "print(f\"Before ReLU:  {hidden1}\")\n",
    "print(f\"After ReLU:  {activations1}\")\n",
    "print(f\"\\n Size after ReLU:  {activations1.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все описанные выше слои можно задать одной последовательностью при помощи подмодуля nn.Sequential:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(flatten, layer1, nn.ReLU(), nn.Linear(512, 10))\n",
    "\n",
    "sample_batch = torch.rand(3, 1, 28, 28)\n",
    "logits = seq_modules(sample_batch)\n",
    "\n",
    "print(f\"Output size: {logits.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И в завершение применим функцию nn.Softmax для предсказания вероятностей выходных классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after Softmax: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "pred_probab = softmax(logits)\n",
    "\n",
    "print(f\"Size after Softmax: {pred_probab.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере ниже мы проходимся по всем параметрам модели, и для каждого тензора параметров выводим его размер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: Network(\n",
      "  (hidden): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (output): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "\n",
      "Layer: hidden.weight              Size: torch.Size([2, 3])\n",
      "Layer: hidden.bias                Size: torch.Size([2])\n",
      "Layer: output.weight              Size: torch.Size([1, 2])\n",
      "Layer: output.bias                Size: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name:25}  Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание: написать архитектуру нейронной сети, на вход которой подаётся изображение размера $28 \\times 28$ с одним скрытым линейным слоем, состоящим из 256 нейронов с функцией активации Sigmoid и выходным слоем, состоящим из 10 нейронов. К выходному слою применить функцию Softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0603, 0.1341, 0.0585, 0.0456, 0.1210, 0.1144, 0.1186, 0.0940, 0.1135,\n",
       "         0.1400]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "input = torch.randn((1, 784))\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "net = Network()\n",
    "net.forward(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор устройства (device) для обучения\n",
    "\n",
    "Мы бы хотели иметь возможность обучать модель на аппаратном ускорителе, таком как GPU, если он доступен. Проверим, доступен ли нам ускоритель [`torch.cuda`](https://pytorch.org/docs/stable/notes/cuda.html), иначе продолжим вычисления на CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание: создать нейронную сеть, указанную на картинке:\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width='1000'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.output = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь запишите эту же нейронную сеть с использованием модуля [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "model1 = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания нейронной сети можно также пользоваться модулем [OrderedDict](https://docs.python.org/3/library/collections.html#collections.OrderedDict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(784, 128)),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(128, 64)),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(64, 10)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы явно увидеть веса модели model2, надо использовать метод parameters():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0185,  0.0117, -0.0328,  ..., -0.0023,  0.0291,  0.0347],\n",
       "         [ 0.0173,  0.0004, -0.0158,  ...,  0.0292, -0.0104, -0.0066],\n",
       "         [-0.0131, -0.0111,  0.0291,  ...,  0.0200,  0.0326, -0.0135],\n",
       "         ...,\n",
       "         [ 0.0107,  0.0037,  0.0211,  ...,  0.0018,  0.0001,  0.0319],\n",
       "         [-0.0082, -0.0328, -0.0322,  ...,  0.0270, -0.0274,  0.0025],\n",
       "         [ 0.0002, -0.0315,  0.0140,  ..., -0.0326,  0.0038, -0.0155]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0098, -0.0255,  0.0026, -0.0221,  0.0253, -0.0177,  0.0300, -0.0059,\n",
       "          0.0042, -0.0075,  0.0234,  0.0103, -0.0227,  0.0232,  0.0061,  0.0057,\n",
       "          0.0006,  0.0237, -0.0055,  0.0279, -0.0250,  0.0197,  0.0300,  0.0024,\n",
       "          0.0278, -0.0213,  0.0045, -0.0029, -0.0008, -0.0162, -0.0286, -0.0316,\n",
       "         -0.0189,  0.0353,  0.0248, -0.0156, -0.0204, -0.0139, -0.0260,  0.0129,\n",
       "          0.0207, -0.0045, -0.0070, -0.0116, -0.0182,  0.0309,  0.0188,  0.0348,\n",
       "         -0.0303,  0.0145,  0.0309,  0.0030, -0.0225,  0.0058,  0.0287,  0.0219,\n",
       "          0.0318, -0.0047,  0.0170,  0.0121, -0.0066, -0.0288,  0.0183,  0.0122,\n",
       "          0.0303,  0.0111, -0.0260,  0.0173,  0.0081,  0.0107,  0.0179,  0.0349,\n",
       "         -0.0244, -0.0212, -0.0157, -0.0254, -0.0273,  0.0034,  0.0114, -0.0008,\n",
       "          0.0334, -0.0026,  0.0185, -0.0302,  0.0118,  0.0104, -0.0284, -0.0266,\n",
       "         -0.0305, -0.0324,  0.0274,  0.0085, -0.0234,  0.0049, -0.0062, -0.0291,\n",
       "         -0.0266, -0.0236,  0.0020,  0.0079,  0.0128,  0.0069, -0.0012, -0.0293,\n",
       "         -0.0096,  0.0160, -0.0275, -0.0307,  0.0114,  0.0134, -0.0161,  0.0028,\n",
       "          0.0301,  0.0211, -0.0046, -0.0350, -0.0084, -0.0156, -0.0107,  0.0332,\n",
       "         -0.0032,  0.0228,  0.0113,  0.0332, -0.0223,  0.0242, -0.0159,  0.0316],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[i for i in model2.fc1.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
