{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1555,
     "status": "ok",
     "timestamp": 1620559384949,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "zKMq7dp2W15Y",
    "outputId": "50cd1b72-e83f-4aa7-d553-533bf1961802"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/noble6/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "nltk.download('punkt')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1540,
     "status": "ok",
     "timestamp": 1620559384950,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "hBkqaK5bawXN",
    "outputId": "4d37ab05-8e21-4e86-adc2-84e2d6ccc572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1620559384951,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "0qOQwNlZbFiO",
    "outputId": "17123e05-c337-4d6c-d12f-2b9aa6f5b68c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/datasets\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WmWCBWxrBUB3"
   },
   "source": [
    "## 1. Генерирование русских имен при помощи RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "990obDBwCC7V"
   },
   "source": [
    "Датасет: https://disk.yandex.ru/i/2yt18jHUgVEoIw\n",
    "\n",
    "1.1 На основе файла name_rus.txt создайте датасет.\n",
    "  * Учтите, что имена могут иметь различную длину\n",
    "  * Добавьте 4 специальных токена: \n",
    "    * `<PAD>` для дополнения последовательности до нужной длины;\n",
    "    * `<UNK>` для корректной обработки ранее не встречавшихся токенов;\n",
    "    * `<SOS>` для обозначения начала последовательности;\n",
    "    * `<EOS>` для обозначения конца последовательности.\n",
    "  * Преобразовывайте строку в последовательность индексов с учетом следующих замечаний:\n",
    "    * в начало последовательности добавьте токен `<SOS>`;\n",
    "    * в конец последовательности добавьте токен `<EOS>` и, при необходимости, несколько токенов `<PAD>`;\n",
    "  * `Dataset.__get_item__` возращает две последовательности: последовательность для обучения и правильный ответ. \n",
    "  \n",
    "  Пример:\n",
    "  ```\n",
    "  s = 'The cat sat on the mat'\n",
    "  # преобразуем в индексы\n",
    "  s_idx = [2, 5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
    "  # получаем x и y (__getitem__)\n",
    "  x = [2, 5, 1, 2, 8, 4, 7, 3, 0]\n",
    "  y = [5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
    "  ```\n",
    "\n",
    "1.2 Создайте и обучите модель для генерации фамилии.\n",
    "\n",
    "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding`;\n",
    "  * Используйте рекуррентные слои;\n",
    "  * Задача ставится как предсказание следующего токена в каждом примере из пакета для каждого момента времени. Т.е. в данный момент времени по текущей подстроке предсказывает следующий символ для данной строки (задача классификации);\n",
    "  * Примерная схема реализации метода `forward`:\n",
    "  ```\n",
    "    input_X: [batch_size x seq_len] -> nn.Embedding -> emb_X: [batch_size x seq_len x embedding_size]\n",
    "    emb_X: [batch_size x seq_len x embedding_size] -> nn.RNN -> output: [batch_size x seq_len x hidden_size] \n",
    "    output: [batch_size x seq_len x hidden_size] -> torch.Tensor.reshape -> output: [batch_size * seq_len x hidden_size]\n",
    "    output: [batch_size * seq_len x hidden_size] -> nn.Linear -> output: [batch_size * seq_len x vocab_size]\n",
    "  ```\n",
    "\n",
    "1.3 Напишите функцию, которая генерирует фамилию при помощи обученной модели:\n",
    "  * Построение начинается с последовательности единичной длины, состоящей из индекса токена `<SOS>`;\n",
    "  * Начальное скрытое состояние RNN `h_t = None`;\n",
    "  * В результате прогона последнего токена из построенной последовательности через модель получаете новое скрытое состояние `h_t` и распределение над всеми токенами из словаря;\n",
    "  * Выбираете 1 токен пропорционально вероятности и добавляете его в последовательность (можно воспользоваться `torch.multinomial`);\n",
    "  * Повторяете эти действия до тех пор, пока не сгенерирован токен `<EOS>` или не превышена максимальная длина последовательности.\n",
    "\n",
    "При обучении каждые `k` эпох генерируйте несколько фамилий и выводите их на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.special_tokens = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.max_len = 0\n",
    "        self.data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                word = line.strip()\n",
    "                self.max_len = max(self.max_len, len(word))\n",
    "                self.data.append(word)\n",
    "                for char in word:\n",
    "                    if char not in self.word2index:\n",
    "                        index = len(self.word2index)\n",
    "                        self.word2index[char] = index\n",
    "                        self.index2word[index] = char\n",
    "        for token in self.special_tokens:\n",
    "            index = len(self.word2index)\n",
    "            self.word2index[token] = index\n",
    "            self.index2word[index] = token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        word = self.data[index]\n",
    "        input_seq = [self.word2index['<SOS>']] + [self.word2index.get(char, self.word2index['<UNK>']) for char in word] + [self.word2index['<EOS>']]\n",
    "        input_seq += [self.word2index['<PAD>']] * (self.max_len - len(input_seq))\n",
    "        target_seq = input_seq[1:] + [self.word2index['<PAD>']]\n",
    "        return torch.tensor(input_seq), torch.tensor(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([32,  0, 18, 19,  7, 21,  7,  9,  4,  0, 33, 30, 30]),\n",
       " tensor([ 0, 18, 19,  7, 21,  7,  9,  4,  0, 33, 30, 30, 30]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = NamesDataset('data/name_rus.txt')\n",
    "print(len(dataset))\n",
    "input_seq, target_seq = dataset[12]\n",
    "\n",
    "input_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[18][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.word2index[\"<EOS>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "# for input_seq, target_seq in dataloader:\n",
    "    # print(input_seq.shape, target_seq.shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[32,  0,  1,  2,  3,  4,  5,  6, 33, 30, 30, 30, 30]]),\n",
       " tensor([[ 0,  1,  2,  3,  4,  5,  6, 33, 30, 30, 30, 30, 30]])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, batch_first=True, num_layers=2)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        emb = self.embedding(input_seq)\n",
    "        output, _ = self.rnn(emb)\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "def generate_name(model, dataset, max_len=20):\n",
    "    with torch.no_grad():\n",
    "        input_seq = torch.tensor([[dataset.word2index['<SOS>']]])\n",
    "        # h_t = None\n",
    "        name = ''\n",
    "        while True:\n",
    "            output = model(input_seq.cuda())\n",
    "            probs = nn.functional.softmax(output[-1], dim=0)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            if next_token == dataset.word2index[\"<EOS>\"] or len(name) >= max_len:\n",
    "                break\n",
    "            name += dataset.index2word[next_token]\n",
    "            input_seq = torch.tensor([[next_token]])\n",
    "            # h_t = output[-1].unsqueeze(0)\n",
    "        return name\n",
    "\n",
    "def train(model, dataloader, dataset, num_epochs, lr, device):\n",
    "    # dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=dataset.word2index['<PAD>'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for input_seq, target_seq in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            # print(123)\n",
    "            input_seq = input_seq.to(device)\n",
    "            target_seq = target_seq.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output, target_seq.reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            names = []\n",
    "            for i in range(2):\n",
    "                name = generate_name(model, dataset)\n",
    "                names.append(name)\n",
    "            print(f\"Предсказанные имена: {names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1988/1988 [00:03<00:00, 543.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 1988/1988 [00:03<00:00, 601.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 2.0733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 1988/1988 [00:03<00:00, 531.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 2.0540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 1988/1988 [00:03<00:00, 599.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 2.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 1988/1988 [00:03<00:00, 573.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 2.0472\n",
      "Предсказанные имена: ['юнчся', 'я']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 1988/1988 [00:03<00:00, 548.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 2.0758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 1988/1988 [00:04<00:00, 489.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 2.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 1988/1988 [00:03<00:00, 597.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 2.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 1988/1988 [00:03<00:00, 609.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 2.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 1988/1988 [00:03<00:00, 629.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 2.0637\n",
      "Предсказанные имена: ['юрюрулюрга', 'я']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 1988/1988 [00:03<00:00, 543.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 2.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 1988/1988 [00:03<00:00, 506.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 2.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 1988/1988 [00:03<00:00, 605.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 2.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 1988/1988 [00:03<00:00, 588.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 2.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 1988/1988 [00:03<00:00, 592.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 2.0221\n",
      "Предсказанные имена: ['юранянозияияняняраня', 'юшаняняня']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 1988/1988 [00:03<00:00, 612.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 2.0569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 1988/1988 [00:03<00:00, 600.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 2.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 1988/1988 [00:03<00:00, 618.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 2.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 1988/1988 [00:03<00:00, 558.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 2.0798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 1988/1988 [00:03<00:00, 601.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 2.0519\n",
      "Предсказанные имена: ['юриянядяня', 'ьяха']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 1988/1988 [00:03<00:00, 563.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 2.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 1988/1988 [00:03<00:00, 603.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 2.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 1988/1988 [00:03<00:00, 609.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 2.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 1988/1988 [00:03<00:00, 589.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 2.0665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 1988/1988 [00:03<00:00, 614.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 2.0475\n",
      "Предсказанные имена: ['юнияй', 'юлия']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 1988/1988 [00:03<00:00, 524.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 2.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 1988/1988 [00:03<00:00, 500.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 2.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 1988/1988 [00:03<00:00, 523.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 2.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 1988/1988 [00:03<00:00, 526.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 2.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 1988/1988 [00:03<00:00, 540.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 2.0397\n",
      "Предсказанные имена: ['юрич', 'юрюряхолич']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 1988/1988 [00:03<00:00, 501.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 2.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 1988/1988 [00:03<00:00, 580.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 2.0391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 1988/1988 [00:04<00:00, 434.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 2.0353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 1988/1988 [00:03<00:00, 533.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 2.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 1988/1988 [00:03<00:00, 594.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 2.0318\n",
      "Предсказанные имена: ['юрася', 'юра']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 1988/1988 [00:03<00:00, 574.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 2.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 1988/1988 [00:03<00:00, 617.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 2.0794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 1988/1988 [00:03<00:00, 600.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 2.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 1988/1988 [00:03<00:00, 522.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 2.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 1988/1988 [00:03<00:00, 549.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 2.0396\n",
      "Предсказанные имена: ['юра', 'исличрана']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 1988/1988 [00:03<00:00, 567.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 2.0535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 1988/1988 [00:03<00:00, 568.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 2.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 1988/1988 [00:03<00:00, 563.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 2.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 1988/1988 [00:03<00:00, 563.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 2.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 1988/1988 [00:03<00:00, 570.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 2.0793\n",
      "Предсказанные имена: ['яхасведич', 'ия']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 1988/1988 [00:03<00:00, 526.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 2.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 1988/1988 [00:03<00:00, 512.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 2.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 1988/1988 [00:04<00:00, 485.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 2.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 1988/1988 [00:03<00:00, 544.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 2.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 1988/1988 [00:03<00:00, 569.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 2.0538\n",
      "Предсказанные имена: ['юранюранич', 'юрадоминярьканилюряр']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(len(dataset.word2index), 16, 32)\n",
    "train(model, dataloader, dataset, 50, 0.01, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = generate_name(model, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'юриадомич'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в файл\n",
    "with open(\"rnn_name_generator.pickle\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели из файла\n",
    "with open(\"rnn_name_generator.pickle\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fJf5iaA2fOTM"
   },
   "source": [
    "## 2. Генерирование текста при помощи RNN\n",
    "\n",
    "2.1 Скачайте из интернета какое-нибудь художественное произведение\n",
    "  * Выбирайте достаточно крупное произведение, чтобы модель лучше обучалась;\n",
    "\n",
    "2.2 На основе выбранного произведения создайте датасет. \n",
    "\n",
    "Отличия от задачи 1:\n",
    "  * Токены <SOS>, `<EOS>` и `<UNK>` можно не добавлять;\n",
    "  * При создании датасета текст необходимо предварительно разбить на части. Выберите желаемую длину последовательности `seq_len` и разбейте текст на построки длины `seq_len` (можно без перекрытия, можно с небольшим перекрытием).\n",
    "\n",
    "2.3 Создайте и обучите модель для генерации текста\n",
    "  * Задача ставится точно так же как в 1.2;\n",
    "  * При необходимости можете применить:\n",
    "    * двухуровневые рекуррентные слои (`num_layers`=2)\n",
    "    * [обрезку градиентов](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
    "\n",
    "2.4 Напишите функцию, которая генерирует фрагмент текста при помощи обученной модели\n",
    "  * Процесс генерации начинается с небольшого фрагмента текста `prime`, выбранного вами (1-2 слова) \n",
    "  * Сначала вы пропускаете через модель токены из `prime` и генерируете на их основе скрытое состояние рекуррентного слоя `h_t`;\n",
    "  * После этого вы генерируете строку нужной длины аналогично 1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 142798\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "with open('data/Война и мир. Том 1.Лев Толстой.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Remove newlines and extra spaces\n",
    "text = text.replace('\\n', ' ').replace('\\r', '').replace('\\t', ' ')\n",
    "text = ' '.join(text.split())\n",
    "\n",
    "seq_len = 100\n",
    "step = 5\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    sentences.append(text[i:i+seq_len])\n",
    "    next_chars.append(text[i+seq_len])\n",
    "\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char to index and index to char dictionaries\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_index = {c: i for i, c in enumerate(chars)}\n",
    "index_to_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class TextGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout=0.5):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        embedded = self.embedding(x)\n",
    "        out, h = self.lstm(embedded, h)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device))\n",
    "\n",
    "input_size = len(string.printable)\n",
    "hidden_size = 256\n",
    "output_size = len(string.printable)\n",
    "\n",
    "model = TextGenerator(input_size, hidden_size, output_size, num_layers=2, dropout=0.5)\n",
    "model.to(\"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, sentences, next_chars, batch_size=128, num_epochs=10, device=\"cuda\"):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        \n",
    "        for i in range(0, len(sentences) - batch_size, batch_size):\n",
    "            inputs = np.zeros((batch_size, seq_len))\n",
    "            targets = np.zeros((batch_size,))\n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                inputs[j] = [char_to_index[c] for c in sentences[i+j]]\n",
    "                targets[j] = char_to_index[next_chars[i+j]]\n",
    "                \n",
    "            inputs = torch.LongTensor(inputs).to(device)\n",
    "            targets = torch.LongTensor(targets).to(device)\n",
    "            \n",
    "            hidden = tuple([h.detach() for h in hidden])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs, hidden = model(inputs, hidden)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '!',\n",
       " 2: \"'\",\n",
       " 3: '(',\n",
       " 4: ')',\n",
       " 5: '*',\n",
       " 6: ',',\n",
       " 7: '-',\n",
       " 8: '.',\n",
       " 9: '0',\n",
       " 10: '1',\n",
       " 11: '2',\n",
       " 12: '3',\n",
       " 13: '4',\n",
       " 14: '5',\n",
       " 15: '6',\n",
       " 16: '7',\n",
       " 17: '8',\n",
       " 18: '9',\n",
       " 19: ':',\n",
       " 20: ';',\n",
       " 21: '?',\n",
       " 22: 'A',\n",
       " 23: 'B',\n",
       " 24: 'C',\n",
       " 25: 'D',\n",
       " 26: 'E',\n",
       " 27: 'F',\n",
       " 28: 'G',\n",
       " 29: 'H',\n",
       " 30: 'I',\n",
       " 31: 'J',\n",
       " 32: 'K',\n",
       " 33: 'L',\n",
       " 34: 'M',\n",
       " 35: 'N',\n",
       " 36: 'O',\n",
       " 37: 'P',\n",
       " 38: 'Q',\n",
       " 39: 'R',\n",
       " 40: 'S',\n",
       " 41: 'T',\n",
       " 42: 'U',\n",
       " 43: 'V',\n",
       " 44: 'W',\n",
       " 45: 'X',\n",
       " 46: 'Z',\n",
       " 47: '[',\n",
       " 48: ']',\n",
       " 49: '`',\n",
       " 50: 'a',\n",
       " 51: 'b',\n",
       " 52: 'c',\n",
       " 53: 'd',\n",
       " 54: 'e',\n",
       " 55: 'f',\n",
       " 56: 'g',\n",
       " 57: 'h',\n",
       " 58: 'i',\n",
       " 59: 'j',\n",
       " 60: 'k',\n",
       " 61: 'l',\n",
       " 62: 'm',\n",
       " 63: 'n',\n",
       " 64: 'o',\n",
       " 65: 'p',\n",
       " 66: 'q',\n",
       " 67: 'r',\n",
       " 68: 's',\n",
       " 69: 't',\n",
       " 70: 'u',\n",
       " 71: 'v',\n",
       " 72: 'w',\n",
       " 73: 'x',\n",
       " 74: 'y',\n",
       " 75: 'z',\n",
       " 76: '«',\n",
       " 77: '»',\n",
       " 78: 'А',\n",
       " 79: 'Б',\n",
       " 80: 'В',\n",
       " 81: 'Г',\n",
       " 82: 'Д',\n",
       " 83: 'Е',\n",
       " 84: 'Ж',\n",
       " 85: 'З',\n",
       " 86: 'И',\n",
       " 87: 'Й',\n",
       " 88: 'К',\n",
       " 89: 'Л',\n",
       " 90: 'М',\n",
       " 91: 'Н',\n",
       " 92: 'О',\n",
       " 93: 'П',\n",
       " 94: 'Р',\n",
       " 95: 'С',\n",
       " 96: 'Т',\n",
       " 97: 'У',\n",
       " 98: 'Ф',\n",
       " 99: 'Х',\n",
       " 100: 'Ц',\n",
       " 101: 'Ч',\n",
       " 102: 'Ш',\n",
       " 103: 'Щ',\n",
       " 104: 'Ь',\n",
       " 105: 'Э',\n",
       " 106: 'Ю',\n",
       " 107: 'Я',\n",
       " 108: 'а',\n",
       " 109: 'б',\n",
       " 110: 'в',\n",
       " 111: 'г',\n",
       " 112: 'д',\n",
       " 113: 'е',\n",
       " 114: 'ж',\n",
       " 115: 'з',\n",
       " 116: 'и',\n",
       " 117: 'й',\n",
       " 118: 'к',\n",
       " 119: 'л',\n",
       " 120: 'м',\n",
       " 121: 'н',\n",
       " 122: 'о',\n",
       " 123: 'п',\n",
       " 124: 'р',\n",
       " 125: 'с',\n",
       " 126: 'т',\n",
       " 127: 'у',\n",
       " 128: 'ф',\n",
       " 129: 'х',\n",
       " 130: 'ц',\n",
       " 131: 'ч',\n",
       " 132: 'ш',\n",
       " 133: 'щ',\n",
       " 134: 'ъ',\n",
       " 135: 'ы',\n",
       " 136: 'ь',\n",
       " 137: 'э',\n",
       " 138: 'ю',\n",
       " 139: 'я',\n",
       " 140: 'ё',\n",
       " 141: '–',\n",
       " 142: '—',\n",
       " 143: '“',\n",
       " 144: '„',\n",
       " 145: '…'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, prime, length, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden(1, device=device)\n",
    "    \n",
    "    prime = [char_to_index[c] for c in prime]\n",
    "    prime = torch.LongTensor(prime).unsqueeze(0).to(device)\n",
    "    \n",
    "    _, hidden = model(prime, hidden)\n",
    "    \n",
    "    generated = prime\n",
    "    \n",
    "    for i in range(length):\n",
    "        outputs, hidden = model(generated[:, -seq_len:], hidden)\n",
    "        _, topi = outputs.topk(1)\n",
    "        generated = torch.cat((generated, topi), dim=1)\n",
    "        \n",
    "    generated = generated.squeeze().tolist()\n",
    "    text = ''.join([index_to_char[i] for i in generated])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, seq_len, step):\n",
    "        self.seq_len = seq_len\n",
    "        self.step = step\n",
    "        \n",
    "        self.sentences = []\n",
    "        self.next_chars = []\n",
    "        for i in range(0, len(text) - seq_len, step):\n",
    "            self.sentences.append(text[i:i+seq_len])\n",
    "            self.next_chars.append(text[i+seq_len])\n",
    "            \n",
    "        self.char_to_index = {c: i for i, c in enumerate(sorted(list(set(text))))}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = [self.char_to_index[c] for c in self.sentences[idx]]\n",
    "        y = self.char_to_index[self.next_chars[idx]]\n",
    "        return torch.LongTensor(x), torch.LongTensor([y])\n",
    "    \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(text, seq_len=30, step=5)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, dataset, num_epochs, lr, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()    \n",
    "        for x, y in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            hidden = model.init_hidden(x.size(0), device)\n",
    "            output, hidden = model(x, hidden)\n",
    "            \n",
    "            loss = criterion(output.view(-1, dataset.vocab_size), y.view(-1))\n",
    "            loss.backward()\n",
    "            \n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            model.eval()\n",
    "            generated_text = generate_text(model, 'Война', 100, device=device)\n",
    "            print(f\"Generated text:\\n{generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1116/1116 [00:07<00:00, 154.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.7449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1116/1116 [00:06<00:00, 161.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 2.3977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1116/1116 [00:06<00:00, 160.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 2.2889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1116/1116 [00:07<00:00, 157.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 2.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1116/1116 [00:07<00:00, 159.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 2.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1116/1116 [00:07<00:00, 159.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 2.1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1116/1116 [00:06<00:00, 161.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 2.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1116/1116 [00:06<00:00, 160.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 2.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1116/1116 [00:07<00:00, 159.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 2.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1116/1116 [00:07<00:00, 152.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 2.0540\n",
      "Generated text:\n",
      "Война с все постарал с в то в то все постарал с в то в то все постарал с в то в то все постарал с в то в \n"
     ]
    }
   ],
   "source": [
    "model = TextGenerator(input_size=dataset.vocab_size, hidden_size=64, output_size=dataset.vocab_size, num_layers=2, dropout=0.5)\n",
    "\n",
    "train(model, dataloader, dataset, num_epochs=10, lr=0.003, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: 100%|██████████| 1116/1116 [00:07<00:00, 155.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 2.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: 100%|██████████| 1116/1116 [00:06<00:00, 160.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40, Loss: 2.0313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: 100%|██████████| 1116/1116 [00:06<00:00, 161.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40, Loss: 2.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: 100%|██████████| 1116/1116 [00:06<00:00, 159.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40, Loss: 2.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: 100%|██████████| 1116/1116 [00:07<00:00, 159.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40, Loss: 1.9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: 100%|██████████| 1116/1116 [00:08<00:00, 139.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40, Loss: 1.9926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: 100%|██████████| 1116/1116 [00:06<00:00, 161.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40, Loss: 1.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: 100%|██████████| 1116/1116 [00:06<00:00, 160.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40, Loss: 1.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: 100%|██████████| 1116/1116 [00:06<00:00, 161.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40, Loss: 1.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: 100%|██████████| 1116/1116 [00:06<00:00, 161.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40, Loss: 1.9626\n",
      "Generated text:\n",
      "Война с своем старал с своем старал с своем старал с своем старал с своем старал с своем старал с своем с\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40: 100%|██████████| 1116/1116 [00:06<00:00, 160.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40, Loss: 1.9619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/40: 100%|██████████| 1116/1116 [00:06<00:00, 160.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40, Loss: 1.9528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/40: 100%|██████████| 1116/1116 [00:06<00:00, 162.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40, Loss: 1.9494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/40: 100%|██████████| 1116/1116 [00:06<00:00, 162.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40, Loss: 1.9442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/40: 100%|██████████| 1116/1116 [00:06<00:00, 161.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40, Loss: 1.9432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/40: 100%|██████████| 1116/1116 [00:06<00:00, 163.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40, Loss: 1.9380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/40: 100%|██████████| 1116/1116 [00:07<00:00, 157.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40, Loss: 1.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/40: 100%|██████████| 1116/1116 [00:06<00:00, 162.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40, Loss: 1.9301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/40: 100%|██████████| 1116/1116 [00:06<00:00, 162.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40, Loss: 1.9238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/40: 100%|██████████| 1116/1116 [00:06<00:00, 162.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40, Loss: 1.9240\n",
      "Generated text:\n",
      "Война и под не под не под не под не выставал он не подложения и под не под не под не под не под не под не\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/40: 100%|██████████| 1116/1116 [00:06<00:00, 163.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40, Loss: 1.9212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/40: 100%|██████████| 1116/1116 [00:07<00:00, 154.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40, Loss: 1.9194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/40:  78%|███████▊  | 874/1116 [00:05<00:01, 157.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/noble6/DEV/Machine_Learning/PyTorch/ML08_GENERATION/08_rnn_generation.ipynb Cell 27\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/noble6/DEV/Machine_Learning/PyTorch/ML08_GENERATION/08_rnn_generation.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(model, dataloader, dataset, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.003\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/home/noble6/DEV/Machine_Learning/PyTorch/ML08_GENERATION/08_rnn_generation.ipynb Cell 27\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/noble6/DEV/Machine_Learning/PyTorch/ML08_GENERATION/08_rnn_generation.ipynb#X40sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/noble6/DEV/Machine_Learning/PyTorch/ML08_GENERATION/08_rnn_generation.ipynb#X40sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/noble6/DEV/Machine_Learning/PyTorch/ML08_GENERATION/08_rnn_generation.ipynb#X40sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/noble6/DEV/Machine_Learning/PyTorch/ML08_GENERATION/08_rnn_generation.ipynb#X40sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/noble6/DEV/Machine_Learning/PyTorch/ML08_GENERATION/08_rnn_generation.ipynb#X40sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m avg_loss \u001b[39m=\u001b[39m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:489\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    487\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_addcdiv_(params_, device_exp_avgs, denom)\n\u001b[1;32m    488\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     bias_correction1 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    490\u001b[0m     bias_correction2 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    492\u001b[0m     step_size \u001b[39m=\u001b[39m _stack_if_compiling([(lr \u001b[39m/\u001b[39m bc) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m bc \u001b[39min\u001b[39;00m bias_correction1])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:489\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    487\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_addcdiv_(params_, device_exp_avgs, denom)\n\u001b[1;32m    488\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     bias_correction1 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    490\u001b[0m     bias_correction2 \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m _get_value(step) \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m device_state_steps]\n\u001b[1;32m    492\u001b[0m     step_size \u001b[39m=\u001b[39m _stack_if_compiling([(lr \u001b[39m/\u001b[39m bc) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m bc \u001b[39min\u001b[39;00m bias_correction1])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:39\u001b[0m, in \u001b[0;36m_get_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m _use_grad\n\u001b[0;32m---> 39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_value\u001b[39m(x):\n\u001b[1;32m     40\u001b[0m     \u001b[39m# item is significantly faster than a cpu tensor in eager mode\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m is_compiling():\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, dataloader, dataset, num_epochs=40, lr=0.003, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Толстой вышел на улицу и приставил с приставил с приставил с приставил с приставил с приставил с приставил с приставил с п\n"
     ]
    }
   ],
   "source": [
    "prime = 'Толстой вышел на улицу'\n",
    "length = 100\n",
    "\n",
    "generated_text = generate_text(model, prime, length)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOt/b54+xoKtnmvuSlliKDY",
   "collapsed_sections": [],
   "name": "blank__08_rnn_generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
