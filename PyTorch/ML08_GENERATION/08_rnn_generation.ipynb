{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1555,
     "status": "ok",
     "timestamp": 1620559384949,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "zKMq7dp2W15Y",
    "outputId": "50cd1b72-e83f-4aa7-d553-533bf1961802"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/noble6/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "nltk.download('punkt')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1540,
     "status": "ok",
     "timestamp": 1620559384950,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "hBkqaK5bawXN",
    "outputId": "4d37ab05-8e21-4e86-adc2-84e2d6ccc572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1620559384951,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "0qOQwNlZbFiO",
    "outputId": "17123e05-c337-4d6c-d12f-2b9aa6f5b68c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/datasets\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WmWCBWxrBUB3"
   },
   "source": [
    "## 1. Генерирование русских имен при помощи RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "990obDBwCC7V"
   },
   "source": [
    "Датасет: https://disk.yandex.ru/i/2yt18jHUgVEoIw\n",
    "\n",
    "1.1 На основе файла name_rus.txt создайте датасет.\n",
    "  * Учтите, что имена могут иметь различную длину\n",
    "  * Добавьте 4 специальных токена: \n",
    "    * `<PAD>` для дополнения последовательности до нужной длины;\n",
    "    * `<UNK>` для корректной обработки ранее не встречавшихся токенов;\n",
    "    * `<SOS>` для обозначения начала последовательности;\n",
    "    * `<EOS>` для обозначения конца последовательности.\n",
    "  * Преобразовывайте строку в последовательность индексов с учетом следующих замечаний:\n",
    "    * в начало последовательности добавьте токен `<SOS>`;\n",
    "    * в конец последовательности добавьте токен `<EOS>` и, при необходимости, несколько токенов `<PAD>`;\n",
    "  * `Dataset.__get_item__` возращает две последовательности: последовательность для обучения и правильный ответ. \n",
    "  \n",
    "  Пример:\n",
    "  ```\n",
    "  s = 'The cat sat on the mat'\n",
    "  # преобразуем в индексы\n",
    "  s_idx = [2, 5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
    "  # получаем x и y (__getitem__)\n",
    "  x = [2, 5, 1, 2, 8, 4, 7, 3, 0]\n",
    "  y = [5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
    "  ```\n",
    "\n",
    "1.2 Создайте и обучите модель для генерации фамилии.\n",
    "\n",
    "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding`;\n",
    "  * Используйте рекуррентные слои;\n",
    "  * Задача ставится как предсказание следующего токена в каждом примере из пакета для каждого момента времени. Т.е. в данный момент времени по текущей подстроке предсказывает следующий символ для данной строки (задача классификации);\n",
    "  * Примерная схема реализации метода `forward`:\n",
    "  ```\n",
    "    input_X: [batch_size x seq_len] -> nn.Embedding -> emb_X: [batch_size x seq_len x embedding_size]\n",
    "    emb_X: [batch_size x seq_len x embedding_size] -> nn.RNN -> output: [batch_size x seq_len x hidden_size] \n",
    "    output: [batch_size x seq_len x hidden_size] -> torch.Tensor.reshape -> output: [batch_size * seq_len x hidden_size]\n",
    "    output: [batch_size * seq_len x hidden_size] -> nn.Linear -> output: [batch_size * seq_len x vocab_size]\n",
    "  ```\n",
    "\n",
    "1.3 Напишите функцию, которая генерирует фамилию при помощи обученной модели:\n",
    "  * Построение начинается с последовательности единичной длины, состоящей из индекса токена `<SOS>`;\n",
    "  * Начальное скрытое состояние RNN `h_t = None`;\n",
    "  * В результате прогона последнего токена из построенной последовательности через модель получаете новое скрытое состояние `h_t` и распределение над всеми токенами из словаря;\n",
    "  * Выбираете 1 токен пропорционально вероятности и добавляете его в последовательность (можно воспользоваться `torch.multinomial`);\n",
    "  * Повторяете эти действия до тех пор, пока не сгенерирован токен `<EOS>` или не превышена максимальная длина последовательности.\n",
    "\n",
    "При обучении каждые `k` эпох генерируйте несколько фамилий и выводите их на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.special_tokens = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.max_len = 0\n",
    "        self.data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                word = line.strip()\n",
    "                self.max_len = max(self.max_len, len(word))\n",
    "                self.data.append(word)\n",
    "                for char in word:\n",
    "                    if char not in self.word2index:\n",
    "                        index = len(self.word2index)\n",
    "                        self.word2index[char] = index\n",
    "                        self.index2word[index] = char\n",
    "        for token in self.special_tokens:\n",
    "            index = len(self.word2index)\n",
    "            self.word2index[token] = index\n",
    "            self.index2word[index] = token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        word = self.data[index]\n",
    "        input_seq = [self.word2index['<SOS>']] + [self.word2index.get(char, self.word2index['<UNK>']) for char in word] + [self.word2index['<EOS>']]\n",
    "        input_seq += [self.word2index['<PAD>']] * (self.max_len - len(input_seq))\n",
    "        target_seq = input_seq[1:] + [self.word2index['<PAD>']]\n",
    "        return torch.tensor(input_seq), torch.tensor(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([32,  0,  2,  0,  8, 33, 30, 30, 30, 30, 30, 30, 30]),\n",
       " tensor([ 0,  2,  0,  8, 33, 30, 30, 30, 30, 30, 30, 30, 30]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = NamesDataset('data/name_rus.txt')\n",
    "print(len(dataset))\n",
    "input_seq, target_seq = dataset[19]\n",
    "\n",
    "input_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[18][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "# for input_seq, target_seq in dataloader:\n",
    "    # print(input_seq.shape, target_seq.shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[32,  0,  1,  2,  3,  4,  5,  6, 33, 30, 30, 30, 30]]),\n",
       " tensor([[ 0,  1,  2,  3,  4,  5,  6, 33, 30, 30, 30, 30, 30]])]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        emb = self.embedding(input_seq)\n",
    "        output, _ = self.rnn(emb)\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "def generate_name(model, dataset, max_len=20):\n",
    "    with torch.no_grad():\n",
    "        input_seq = torch.tensor([[dataset.special_tokens['<SOS>']]])\n",
    "        # h_t = None\n",
    "        name = ''\n",
    "        while True:\n",
    "            output = model(input_seq.cuda())\n",
    "            probs = nn.functional.softmax(output[-1], dim=0)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            if next_token == dataset.special_tokens['<EOS>'] or len(name) >= max_len:\n",
    "                break\n",
    "            name += dataset.index2word[next_token]\n",
    "            input_seq = torch.tensor([[next_token]])\n",
    "            # h_t = output[-1].unsqueeze(0)\n",
    "        return name\n",
    "\n",
    "def train(model, dataloader, dataset, num_epochs, lr, device):\n",
    "    # dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=dataset.special_tokens['<PAD>'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for input_seq, target_seq in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            # print(123)\n",
    "            input_seq = input_seq.to(device)\n",
    "            target_seq = target_seq.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output, target_seq.reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            names = []\n",
    "            for i in range(2):\n",
    "                name = generate_name(model, dataset)\n",
    "                names.append(name)\n",
    "            print(f\"Предсказанные имена: {names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1988/1988 [00:03<00:00, 545.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 1988/1988 [00:03<00:00, 604.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 1.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 1988/1988 [00:03<00:00, 587.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 1.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 1988/1988 [00:03<00:00, 577.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 1.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 1988/1988 [00:03<00:00, 593.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 1.0896\n",
      "Предсказанные имена: ['ич<EOS><PAD><PAD><PAD>', 'юрилюрий<EOS><PAD><PAD>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 1988/1988 [00:03<00:00, 594.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 1.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 1988/1988 [00:03<00:00, 639.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 1.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 1988/1988 [00:03<00:00, 600.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 1.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 1988/1988 [00:03<00:00, 617.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 1.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 1988/1988 [00:03<00:00, 574.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 1.1304\n",
      "Предсказанные имена: ['усюсютюнюсизи', 'к<PAD><PAD><PAD><PAD>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 1988/1988 [00:03<00:00, 624.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 1.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 1988/1988 [00:03<00:00, 562.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 1.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 1988/1988 [00:03<00:00, 546.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 1.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 1988/1988 [00:03<00:00, 539.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 1.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 1988/1988 [00:03<00:00, 585.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 1.0829\n",
      "Предсказанные имена: ['улюрит', 'унуня<EOS><PAD><PAD>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 1988/1988 [00:03<00:00, 523.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 1.0959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 1988/1988 [00:03<00:00, 520.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 1.0932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 1988/1988 [00:03<00:00, 617.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 1.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 1988/1988 [00:03<00:00, 608.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 1.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 1988/1988 [00:03<00:00, 524.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 1.1083\n",
      "Предсказанные имена: ['уря<EOS><PAD><PAD><PAD>', 'уст']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 1988/1988 [00:03<00:00, 508.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 1.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 1988/1988 [00:03<00:00, 568.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 1.0966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 1988/1988 [00:03<00:00, 601.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 1.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 1988/1988 [00:03<00:00, 535.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 1.1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 1988/1988 [00:03<00:00, 560.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 1.0897\n",
      "Предсказанные имена: ['улийрурийлюрурийрули', 'пур']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 1988/1988 [00:04<00:00, 477.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 1.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 1988/1988 [00:03<00:00, 592.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 1.0986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 1988/1988 [00:03<00:00, 607.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 1.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 1988/1988 [00:03<00:00, 629.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 1.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 1988/1988 [00:03<00:00, 610.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 1.1156\n",
      "Предсказанные имена: ['урияхур', 'урийлурил']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 1988/1988 [00:03<00:00, 597.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 1.0993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 1988/1988 [00:03<00:00, 579.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 1.0986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 1988/1988 [00:03<00:00, 603.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 1.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 1988/1988 [00:03<00:00, 610.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 1.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 1988/1988 [00:03<00:00, 603.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 1.1034\n",
      "Предсказанные имена: ['унюсирилюс', 'урилюнюриририрулюрил']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 1988/1988 [00:03<00:00, 598.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 1.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 1988/1988 [00:03<00:00, 597.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 1.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 1988/1988 [00:03<00:00, 606.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 1.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 1988/1988 [00:03<00:00, 579.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 1.0849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 1988/1988 [00:03<00:00, 594.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 1.1287\n",
      "Предсказанные имена: ['юрий', 'уильжмийля<EOS><PAD>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 1988/1988 [00:03<00:00, 597.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 1.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 1988/1988 [00:03<00:00, 625.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 1.1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 1988/1988 [00:03<00:00, 612.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 1.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 1988/1988 [00:03<00:00, 599.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 1.1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 1988/1988 [00:03<00:00, 558.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 1.0968\n",
      "Предсказанные имена: ['стиня<EOS><PAD><PAD>', 'сюнякстичнюня<EOS><PAD>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 1988/1988 [00:03<00:00, 550.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 1.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 1988/1988 [00:03<00:00, 592.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 1.0777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 1988/1988 [00:03<00:00, 549.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 1.0993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 1988/1988 [00:03<00:00, 564.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 1.1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 1988/1988 [00:03<00:00, 567.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 1.0986\n",
      "Предсказанные имена: ['р', 'стиря<EOS><PAD><PAD>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(len(dataset.word2index), 16, 32)\n",
    "train(model, dataloader, dataset, 50, 0.01, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = generate_name(model, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'жюня<EOS><PAD><PAD><PAD>'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fJf5iaA2fOTM"
   },
   "source": [
    "## 2. Генерирование текста при помощи RNN\n",
    "\n",
    "2.1 Скачайте из интернета какое-нибудь художественное произведение\n",
    "  * Выбирайте достаточно крупное произведение, чтобы модель лучше обучалась;\n",
    "\n",
    "2.2 На основе выбранного произведения создайте датасет. \n",
    "\n",
    "Отличия от задачи 1:\n",
    "  * Токены <SOS>, `<EOS>` и `<UNK>` можно не добавлять;\n",
    "  * При создании датасета текст необходимо предварительно разбить на части. Выберите желаемую длину последовательности `seq_len` и разбейте текст на построки длины `seq_len` (можно без перекрытия, можно с небольшим перекрытием).\n",
    "\n",
    "2.3 Создайте и обучите модель для генерации текста\n",
    "  * Задача ставится точно так же как в 1.2;\n",
    "  * При необходимости можете применить:\n",
    "    * двухуровневые рекуррентные слои (`num_layers`=2)\n",
    "    * [обрезку градиентов](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
    "\n",
    "2.4 Напишите функцию, которая генерирует фрагмент текста при помощи обученной модели\n",
    "  * Процесс генерации начинается с небольшого фрагмента текста `prime`, выбранного вами (1-2 слова) \n",
    "  * Сначала вы пропускаете через модель токены из `prime` и генерируете на их основе скрытое состояние рекуррентного слоя `h_t`;\n",
    "  * После этого вы генерируете строку нужной длины аналогично 1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 142798\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "with open('data/Война и мир. Том 1.Лев Толстой.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Remove newlines and extra spaces\n",
    "text = text.replace('\\n', ' ').replace('\\r', '').replace('\\t', ' ')\n",
    "text = ' '.join(text.split())\n",
    "\n",
    "seq_len = 100\n",
    "step = 5\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    sentences.append(text[i:i+seq_len])\n",
    "    next_chars.append(text[i+seq_len])\n",
    "\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char to index and index to char dictionaries\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_index = {c: i for i, c in enumerate(chars)}\n",
    "index_to_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class TextGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout=0.5):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        embedded = self.embedding(x)\n",
    "        out, h = self.lstm(embedded, h)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device))\n",
    "\n",
    "input_size = len(string.printable)\n",
    "hidden_size = 256\n",
    "output_size = len(string.printable)\n",
    "\n",
    "model = TextGenerator(input_size, hidden_size, output_size, num_layers=2, dropout=0.5)\n",
    "model.to(\"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, sentences, next_chars, batch_size=128, num_epochs=10, device=\"cuda\"):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        \n",
    "        for i in range(0, len(sentences) - batch_size, batch_size):\n",
    "            inputs = np.zeros((batch_size, seq_len))\n",
    "            targets = np.zeros((batch_size,))\n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                inputs[j] = [char_to_index[c] for c in sentences[i+j]]\n",
    "                targets[j] = char_to_index[next_chars[i+j]]\n",
    "                \n",
    "            inputs = torch.LongTensor(inputs).to(device)\n",
    "            targets = torch.LongTensor(targets).to(device)\n",
    "            \n",
    "            hidden = tuple([h.detach() for h in hidden])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs, hidden = model(inputs, hidden)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '!',\n",
       " 2: \"'\",\n",
       " 3: '(',\n",
       " 4: ')',\n",
       " 5: '*',\n",
       " 6: ',',\n",
       " 7: '-',\n",
       " 8: '.',\n",
       " 9: '0',\n",
       " 10: '1',\n",
       " 11: '2',\n",
       " 12: '3',\n",
       " 13: '4',\n",
       " 14: '5',\n",
       " 15: '6',\n",
       " 16: '7',\n",
       " 17: '8',\n",
       " 18: '9',\n",
       " 19: ':',\n",
       " 20: ';',\n",
       " 21: '?',\n",
       " 22: 'A',\n",
       " 23: 'B',\n",
       " 24: 'C',\n",
       " 25: 'D',\n",
       " 26: 'E',\n",
       " 27: 'F',\n",
       " 28: 'G',\n",
       " 29: 'H',\n",
       " 30: 'I',\n",
       " 31: 'J',\n",
       " 32: 'K',\n",
       " 33: 'L',\n",
       " 34: 'M',\n",
       " 35: 'N',\n",
       " 36: 'O',\n",
       " 37: 'P',\n",
       " 38: 'Q',\n",
       " 39: 'R',\n",
       " 40: 'S',\n",
       " 41: 'T',\n",
       " 42: 'U',\n",
       " 43: 'V',\n",
       " 44: 'W',\n",
       " 45: 'X',\n",
       " 46: 'Z',\n",
       " 47: '[',\n",
       " 48: ']',\n",
       " 49: '`',\n",
       " 50: 'a',\n",
       " 51: 'b',\n",
       " 52: 'c',\n",
       " 53: 'd',\n",
       " 54: 'e',\n",
       " 55: 'f',\n",
       " 56: 'g',\n",
       " 57: 'h',\n",
       " 58: 'i',\n",
       " 59: 'j',\n",
       " 60: 'k',\n",
       " 61: 'l',\n",
       " 62: 'm',\n",
       " 63: 'n',\n",
       " 64: 'o',\n",
       " 65: 'p',\n",
       " 66: 'q',\n",
       " 67: 'r',\n",
       " 68: 's',\n",
       " 69: 't',\n",
       " 70: 'u',\n",
       " 71: 'v',\n",
       " 72: 'w',\n",
       " 73: 'x',\n",
       " 74: 'y',\n",
       " 75: 'z',\n",
       " 76: '«',\n",
       " 77: '»',\n",
       " 78: 'А',\n",
       " 79: 'Б',\n",
       " 80: 'В',\n",
       " 81: 'Г',\n",
       " 82: 'Д',\n",
       " 83: 'Е',\n",
       " 84: 'Ж',\n",
       " 85: 'З',\n",
       " 86: 'И',\n",
       " 87: 'Й',\n",
       " 88: 'К',\n",
       " 89: 'Л',\n",
       " 90: 'М',\n",
       " 91: 'Н',\n",
       " 92: 'О',\n",
       " 93: 'П',\n",
       " 94: 'Р',\n",
       " 95: 'С',\n",
       " 96: 'Т',\n",
       " 97: 'У',\n",
       " 98: 'Ф',\n",
       " 99: 'Х',\n",
       " 100: 'Ц',\n",
       " 101: 'Ч',\n",
       " 102: 'Ш',\n",
       " 103: 'Щ',\n",
       " 104: 'Ь',\n",
       " 105: 'Э',\n",
       " 106: 'Ю',\n",
       " 107: 'Я',\n",
       " 108: 'а',\n",
       " 109: 'б',\n",
       " 110: 'в',\n",
       " 111: 'г',\n",
       " 112: 'д',\n",
       " 113: 'е',\n",
       " 114: 'ж',\n",
       " 115: 'з',\n",
       " 116: 'и',\n",
       " 117: 'й',\n",
       " 118: 'к',\n",
       " 119: 'л',\n",
       " 120: 'м',\n",
       " 121: 'н',\n",
       " 122: 'о',\n",
       " 123: 'п',\n",
       " 124: 'р',\n",
       " 125: 'с',\n",
       " 126: 'т',\n",
       " 127: 'у',\n",
       " 128: 'ф',\n",
       " 129: 'х',\n",
       " 130: 'ц',\n",
       " 131: 'ч',\n",
       " 132: 'ш',\n",
       " 133: 'щ',\n",
       " 134: 'ъ',\n",
       " 135: 'ы',\n",
       " 136: 'ь',\n",
       " 137: 'э',\n",
       " 138: 'ю',\n",
       " 139: 'я',\n",
       " 140: 'ё',\n",
       " 141: '–',\n",
       " 142: '—',\n",
       " 143: '“',\n",
       " 144: '„',\n",
       " 145: '…'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, prime, length, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden(1, device=device)\n",
    "    \n",
    "    prime = [char_to_index[c] for c in prime]\n",
    "    prime = torch.LongTensor(prime).unsqueeze(0).to(device)\n",
    "    \n",
    "    _, hidden = model(prime, hidden)\n",
    "    \n",
    "    generated = prime\n",
    "    \n",
    "    for i in range(length):\n",
    "        outputs, hidden = model(generated[:, -seq_len:], hidden)\n",
    "        _, topi = outputs.topk(1)\n",
    "        generated = torch.cat((generated, topi), dim=1)\n",
    "        \n",
    "    generated = generated.squeeze().tolist()\n",
    "    text = ''.join([index_to_char[i] for i in generated])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, seq_len, step):\n",
    "        self.seq_len = seq_len\n",
    "        self.step = step\n",
    "        \n",
    "        self.sentences = []\n",
    "        self.next_chars = []\n",
    "        for i in range(0, len(text) - seq_len, step):\n",
    "            self.sentences.append(text[i:i+seq_len])\n",
    "            self.next_chars.append(text[i+seq_len])\n",
    "            \n",
    "        self.char_to_index = {c: i for i, c in enumerate(sorted(list(set(text))))}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = [self.char_to_index[c] for c in self.sentences[idx]]\n",
    "        y = self.char_to_index[self.next_chars[idx]]\n",
    "        return torch.LongTensor(x), torch.LongTensor([y])\n",
    "    \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(text, seq_len=30, step=5)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, dataset, num_epochs, lr, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()    \n",
    "        for x, y in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            hidden = model.init_hidden(x.size(0), device)\n",
    "            output, hidden = model(x, hidden)\n",
    "            \n",
    "            loss = criterion(output.view(-1, dataset.vocab_size), y.view(-1))\n",
    "            loss.backward()\n",
    "            \n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "        \n",
    "        if (epoch+1) % 1 == 0:\n",
    "            model.eval()\n",
    "            generated_text = generate_text(model, 'Война', 100, device=device)\n",
    "            print(f\"Generated text:\\n{generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1116/1116 [00:08<00:00, 135.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.7462\n",
      "Generated text:\n",
      "Война стори стори стори стори стори стори стори стори стори стори стори стори стори стори стори стори сто\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1116/1116 [00:07<00:00, 146.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 2.4133\n",
      "Generated text:\n",
      "Война в сторовой в сторовой в сторовой в сторовой в сторовой в сторовой в сторовой в сторовой в сторовой \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1116/1116 [00:07<00:00, 144.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 2.3019\n",
      "Generated text:\n",
      "Война сторовал сторовал сторовал сторовал сторовал сторовал сторовал сторовал сторовал сторовал сторовал \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1116/1116 [00:07<00:00, 142.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 2.2359\n",
      "Generated text:\n",
      "Войнали и подолодали и подолодали и подолодали и подолодали и подолодали и подолодали и подолодали и подо\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1116/1116 [00:07<00:00, 144.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 2.1885\n",
      "Generated text:\n",
      "Война с подорошил с подорошил с подорошил с подорошил с подорошил с подорошил с подорошил с подорошил с п\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1116/1116 [00:07<00:00, 142.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 2.1543\n",
      "Generated text:\n",
      "Война сторовал сторовал сторовал сторовал сторовал сторовал сторовал сторовал сторовал сторовал сторовал \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1116/1116 [00:07<00:00, 144.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 2.1258\n",
      "Generated text:\n",
      "Войная в старовал он старать с старовал он старать с старовал он старать с старовал он старать с старовал\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1116/1116 [00:07<00:00, 146.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 2.1009\n",
      "Generated text:\n",
      "Войная и старал в постал в постал в постал в постал в постал в постал в постал в постал в постал в постал\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1116/1116 [00:07<00:00, 141.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 2.0838\n",
      "Generated text:\n",
      "Войная и не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не не \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1116/1116 [00:08<00:00, 138.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 2.0676\n",
      "Generated text:\n",
      "Войная с пришел с пришел солдатом своем своем своем своем своем своем с пришел солдатом своем своем своем\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = TextGenerator(input_size=dataset.vocab_size, hidden_size=64, output_size=dataset.vocab_size, num_layers=2, dropout=0.5)\n",
    "\n",
    "train(model, dataloader, dataset, num_epochs=10, lr=0.003, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Толстой солдатом своем своем своем своем своем своем своем с пришел солдатом своем своем своем своем своем \n"
     ]
    }
   ],
   "source": [
    "prime = 'Толстой'\n",
    "length = 100\n",
    "\n",
    "generated_text = generate_text(model, prime, length)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOt/b54+xoKtnmvuSlliKDY",
   "collapsed_sections": [],
   "name": "blank__08_rnn_generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
